---
title: 시선 응시 기반 상호 작용
description: Holographic 환경에서 사용 하는 경우 HoloLens 2와 새로운 수준의 컨텍스트 및 인간 이해에 대 한 눈에 기반을 두는 방법에 대해 알아봅니다.
author: sostel
ms.author: sostel
ms.date: 10/29/2019
ms.topic: article
keywords: 눈 추적, 혼합 현실, 입력, 눈동자-응시, 혼합 현실 헤드셋, windows mixed reality 헤드셋, 가상 현실 헤드셋, HoloLens, MRTK, 혼합 현실 도구 키트, 디자인, 상호 작용
ms.openlocfilehash: db3cb774d72de13c2f1e51d446969ee7a4cdf2b7
ms.sourcegitcommit: d3a3b4f13b3728cfdd4d43035c806c0791d3f2fe
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 01/20/2021
ms.locfileid: "98582388"
---
# <a name="eye-gaze-based-interaction-on-hololens-2"></a><span data-ttu-id="e5527-104">HoloLens의 눈동자 기반 상호 작용 2</span><span class="sxs-lookup"><span data-stu-id="e5527-104">Eye-gaze-based interaction on HoloLens 2</span></span>

![MRTK의 아이 추적 데모](images/mrtk_et_scenemenu.jpg)

<span data-ttu-id="e5527-106">HoloLens 2에 대 한 흥미로운 새로운 기능 중 하나는 눈 추적입니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-106">One of our exciting new capabilities on HoloLens 2 is eye tracking.</span></span> <span data-ttu-id="e5527-107">[HoloLens의 눈동자 추적 2](eye-tracking.md) 페이지에서는 몇 가지 개발자 지침을 제공 하 고 눈 추적을 위해 강조 된 사용 사례를 제공 하는 각 사용자가 [보정](/hololens/hololens-calibration)을 수행 해야 하는 필요성에 대해 설명 했습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-107">On our [Eye tracking on HoloLens 2](eye-tracking.md) page, we mentioned the need for each user to go through a [Calibration](/hololens/hololens-calibration), provided some developer guidance, and highlighted use cases for eye tracking.</span></span> <span data-ttu-id="e5527-108">눈동자-응시 입력은 여전히 새로운 유형의 사용자 입력 이며 배워야 할 내용이 많습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-108">Eye-gaze input is still a new type of user input and there's a lot to learn.</span></span> 

<span data-ttu-id="e5527-109">눈에 잘 맞는 입력은 Holographic Shell 환경 (HoloLens 2를 시작할 때 표시 되는 사용자 인터페이스)에서 약간만 사용 되지만 ["hololens 탭"](https://www.microsoft.com/p/mr-playground/9nb31lh723s2)과 같은 여러 앱은 눈에 입력이 Holographic 환경의 매직에 추가 되는 방법에 대 한 좋은 예를 보여 줍니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-109">While eye-gaze input is only used subtly in our Holographic Shell experience (the user interface that you see when you start your HoloLens 2), several apps, such as the ["HoloLens Playground"](https://www.microsoft.com/p/mr-playground/9nb31lh723s2), showcase great examples on how eye-gaze input can add to the magic of your holographic experience.</span></span>
<span data-ttu-id="e5527-110">이 페이지에서는 holographic 응용 프로그램과 상호 작용 하기 위해 눈 응시 입력을 통합 하기 위한 디자인 고려 사항에 대해 설명 합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-110">On this page, we discuss design considerations for integrating eye-gaze input to interact with your holographic applications.</span></span>

<span data-ttu-id="e5527-111">주요 이점 및 눈에 잘 맞는 입력으로 제공 되는 고유한 과제에 대해 알아봅니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-111">You'll learn about key advantages and also unique challenges that come with eye-gaze input.</span></span> <span data-ttu-id="e5527-112">이를 기반으로 하는 다양 한 디자인 권장 사항을 제공 하 여 눈길을 가진 눈길을 지 원하는 사용자 인터페이스를 만드는 데 도움을 줍니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-112">Based on these, we provide several design recommendations to help you create satisfying eye-gaze-supported user interfaces.</span></span> 

## <a name="device-support"></a><span data-ttu-id="e5527-113">디바이스 지원</span><span class="sxs-lookup"><span data-stu-id="e5527-113">Device support</span></span>

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="e5527-114"><strong>기능</strong></span><span class="sxs-lookup"><span data-stu-id="e5527-114"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="e5527-115"><a href="/hololens/hololens1-hardware"><strong>HoloLens(1세대)</strong></a></span><span class="sxs-lookup"><span data-stu-id="e5527-115"><a href="/hololens/hololens1-hardware"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="e5527-116"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="e5527-116"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="e5527-117"><a href="../discover/immersive-headset-hardware-details.md"><strong>몰입형 헤드셋</strong></a></span><span class="sxs-lookup"><span data-stu-id="e5527-117"><a href="../discover/immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="e5527-118">눈-응시</span><span class="sxs-lookup"><span data-stu-id="e5527-118">Eye-gaze</span></span></td>
     <td>❌</td>
     <td><span data-ttu-id="e5527-119">✔️</span><span class="sxs-lookup"><span data-stu-id="e5527-119">✔️</span></span></td>
     <td>❌</td>
</tr>
</table>


## <a name="eye-gaze-input-design-guidelines"></a><span data-ttu-id="e5527-120">눈동자-응시 입력 디자인 지침</span><span class="sxs-lookup"><span data-stu-id="e5527-120">Eye-gaze input design guidelines</span></span>

<span data-ttu-id="e5527-121">빠른 이동 대상 지정을 활용 하는 상호 작용을 빌드하는 것은 어려울 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-121">Building an interaction that takes advantage of fast-moving eye targeting can be challenging.</span></span> <span data-ttu-id="e5527-122">이 섹션에서는 응용 프로그램을 디자인할 때 고려해 야 할 주요 이점 및 과제를 요약 합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-122">In this section, we summarize the key advantages and challenges to consider when designing your application.</span></span> 

### <a name="benefits-of-eye-gaze-input"></a><span data-ttu-id="e5527-123">눈에 주목 하는 입력의 이점</span><span class="sxs-lookup"><span data-stu-id="e5527-123">Benefits of eye-gaze input</span></span>

- <span data-ttu-id="e5527-124">**고속 가리키기.**</span><span class="sxs-lookup"><span data-stu-id="e5527-124">**High speed pointing.**</span></span> <span data-ttu-id="e5527-125">눈 muscle는 인간 본문에서 가장 빠른 대응 muscle입니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-125">The eye muscle is the fastest reacting muscle in the human body.</span></span> 

- <span data-ttu-id="e5527-126">**적은 노력.**</span><span class="sxs-lookup"><span data-stu-id="e5527-126">**Low effort.**</span></span> <span data-ttu-id="e5527-127">신체 움직임은 거의 필요하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-127">Barely any physical movements are necessary.</span></span> 

- <span data-ttu-id="e5527-128">**암시성.**</span><span class="sxs-lookup"><span data-stu-id="e5527-128">**Implicitness.**</span></span> <span data-ttu-id="e5527-129">사용자가 "마인드 읽기"로 설명 하는 경우가 많으므로 사용자의 눈 이동에 대 한 정보는 시스템에서 사용자가 참여 하는 대상을 알 수 있도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-129">Often described by users as "mind reading", information about a user's eye movements lets the system know which target the user plans to engage.</span></span> 

- <span data-ttu-id="e5527-130">**대체 입력 채널.**</span><span class="sxs-lookup"><span data-stu-id="e5527-130">**Alternative input channel.**</span></span> <span data-ttu-id="e5527-131">눈동자-응시는 직접 조정에 따라 사용자의 경험에 대 한 직접 및 음성 입력을 위한 강력한 지원 입력을 제공할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-131">Eye-gaze can provide a powerful supporting input for hand and voice input building on years of experience from users based on their hand-eye coordination.</span></span>

- <span data-ttu-id="e5527-132">**시각적 주의.**</span><span class="sxs-lookup"><span data-stu-id="e5527-132">**Visual attention.**</span></span> <span data-ttu-id="e5527-133">또 다른 중요 한 혜택은 사용자가 주의를 기울여야 하는 항목을 유추할 수 있다는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-133">Another important benefit is the possibility to infer what a user is paying attention to.</span></span> <span data-ttu-id="e5527-134">이렇게 하면 다양 한 디자인을 보다 효과적으로 평가 하 여 보다 효율적인 사용자 인터페이스 및 원격 통신에 대 한 향상 된 소셜 큐를 구체적 하는 다양 한 응용 프로그램 영역에서 도움이 됩니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-134">This can help in various application areas ranging from more effectively evaluating different designs to aiding in smarter user interfaces and enhanced social cues for remote communication.</span></span>

<span data-ttu-id="e5527-135">간단히 말해서, 입력으로 눈동자-응시를 사용 하면 빠르고 손쉬운 컨텍스트 입력 신호를 제공 합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-135">In a nutshell, using eye-gaze as an input offers a fast and effortless contextual input signal.</span></span> <span data-ttu-id="e5527-136">*음성* 및 *수동* 입력과 같이 사용자의 의도를 확인 하는 다른 입력과 함께 사용 하면 강력한 기능입니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-136">This is powerful when combined with other inputs such as *voice* and *manual* input to confirm the user's intent.</span></span>


### <a name="challenges-of-eye-gaze-as-an-input"></a><span data-ttu-id="e5527-137">눈에 직면 하는 문제-입력을 입력 합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-137">Challenges of eye-gaze as an input</span></span>

<span data-ttu-id="e5527-138">눈에 superhero를 사용 하 여 마음에 들지 않는 사용자 환경을 만들 수 있지만,이를 적절 하 게 고려 하는 것이 적절 하지 않을 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-138">While eye-gaze can be used to create satisfying user experiences, which make you feel like a superhero, it's also important to know what it isn't good at to appropriately account for this.</span></span> <span data-ttu-id="e5527-139">다음 목록에서는 고려해 야 할 몇 가지 *문제와* 눈에 잘 된 입력을 사용할 때 해결 하는 방법을 설명 합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-139">The following list discusses some *challenges* to consider and how to address them when working with eye-gaze input:</span></span> 

- <span data-ttu-id="e5527-140">**눈에 주목 하는 것은 "always on"입니다** . 눈 뚜껑을 여는 순간은 환경에서 무언가를 시작 합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-140">**Your eye-gaze is "always on"** The moment you open your eye lids, your eyes start fixating on things in the environment.</span></span> <span data-ttu-id="e5527-141">사용자가 작업을 수행 하 고 실수로 작업을 실행 하는 경우에는 너무 오래 된 작업에 대 한 응답으로 인해 만족 하지 않는 환경이 발생 합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-141">Reacting to every look you make and accidentally issuing actions, because you looked at something for too long, would result in an unsatisfying experience.</span></span>
<span data-ttu-id="e5527-142">눈에 잘 맞는 *음성 명령*, *손 모양 제스처*, *단추 클릭* 또는 확장 된 유지를 결합 하 여 대상을 선택 하는 것이 좋습니다 (자세한 내용은 [눈에 잘 맞는-응시 및 커밋](gaze-and-commit-eyes.md)참조).</span><span class="sxs-lookup"><span data-stu-id="e5527-142">We recommend combining eye-gaze with a *voice command*, *hand gesture*, *button click* or extended dwell to trigger the selection of a target (for more information, see [eye-gaze and commit](gaze-and-commit-eyes.md)).</span></span>
<span data-ttu-id="e5527-143">또한이 솔루션을 사용 하면 사용자가 무언가를 involuntarily 하 여 너무 부담 없이 자유롭게 볼 수 있는 모드를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-143">This solution also allows for a mode in which the user can freely look around without being overwhelmed by involuntarily triggering something.</span></span> <span data-ttu-id="e5527-144">대상을 확인할 때 시각적 개체와 청각 피드백을 디자인할 때에도이 문제를 고려해 야 합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-144">This issue should also be considered when designing visual and auditory feedback when looking at a target.</span></span>
<span data-ttu-id="e5527-145">즉시 팝아웃 효과를 사용 하거나 소리를 가리키기 위해 사용자에 게 과부하가 걸리지 않도록 시도 합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-145">Try not to overwhelm the user with immediate pop-out effects or hover sounds.</span></span> <span data-ttu-id="e5527-146">미묘한는 키입니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-146">Subtlety is key.</span></span> <span data-ttu-id="e5527-147">[디자인 권장 사항](eye-gaze-interaction.md#design-recommendations)에 대해 논의할 때이에 대 한 몇 가지 모범 사례를 설명 하겠습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-147">We'll discuss some best practices for this further below when talking about [design recommendations](eye-gaze-interaction.md#design-recommendations).</span></span>

- <span data-ttu-id="e5527-148">**관찰 및 제어** 벽에 사진을 정확 하 게 똑바르게 하려고 한다고 가정 합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-148">**Observation vs. control** Imagine that you want to precisely straighten a photograph on your wall.</span></span> <span data-ttu-id="e5527-149">벽에 맞는지 보기 위해 테두리와 주변을 보게 됩니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-149">You look at its borders and its surroundings to see if it aligns well.</span></span> <span data-ttu-id="e5527-150">이제 눈을 입력으로 사용 하 여 그림을 이동 하려는 경우이 작업을 수행 하는 방법을 상상해 보세요.</span><span class="sxs-lookup"><span data-stu-id="e5527-150">Now imagine how you would do that when you want to use your eye-gaze as an input to move the picture.</span></span> <span data-ttu-id="e5527-151">어렵죠. 그렇지 않나요?</span><span class="sxs-lookup"><span data-stu-id="e5527-151">Difficult, isn't it?</span></span> <span data-ttu-id="e5527-152">이는 입력 및 제어에 모두 필요한 경우 눈에 주목 하는 이중 역할을 설명 합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-152">This describes the double role of eye-gaze when it's required both for input and control.</span></span> 

- <span data-ttu-id="e5527-153">**클릭 전에 나가기:** 빠른 대상 선택을 위해 수동 클릭 (예: 공중 탭)을 마무리 하기 전에 사용자의 눈 응시가 이동할 수 있다는 것을 연구 했습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-153">**Leave before click:** For quick target selections, research has shown that a user's eye-gaze can move on before concluding a manual click (for example, an air tap).</span></span> <span data-ttu-id="e5527-154">빠른 시각-응시 신호를 느린 제어 입력 (예: 음성, 실습, 컨트롤러)과 동기화 하는 데 특히 주의 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-154">Pay special attention to synchronizing the fast eye-gaze signal with slower control input (for example, voice, hands, controller).</span></span>

- <span data-ttu-id="e5527-155">**작은 대상:** 너무 작아서 편안 하 게 읽을 수 없는 텍스트를 읽으려고 할 때의 느낌이 있나요?</span><span class="sxs-lookup"><span data-stu-id="e5527-155">**Small targets:** Do you know the feeling when you try to read text that is just a bit too small to read comfortably?</span></span> <span data-ttu-id="e5527-156">눈에 덕분 눈에 다시 조정 하는 것이 좋을 것입니다 .이로 인해 눈에.</span><span class="sxs-lookup"><span data-stu-id="e5527-156">This straining feeling on your eyes can cause you to feel tired and worn out, because you try to readjust your eyes to focus better.</span></span>
<span data-ttu-id="e5527-157">이는 사용자가 눈동자 대상을 사용 하 여 응용 프로그램에 너무 작은 대상을 선택할 때 사용자에 게 호출할 수 있는 느낌입니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-157">This is a feeling you might invoke in your users when forcing them to select targets that are too small in your application using eye targeting.</span></span>
<span data-ttu-id="e5527-158">사용자를 위해 기분 좋고 편리한 환경을 디자인하려면 대상에 대한 시각적 각도를 2° 이상으로 유지하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-158">For your design, to create a pleasant and comfortable experience for your users, we recommend that targets should be at least 2° in visual angle, preferably larger.</span></span>

- <span data-ttu-id="e5527-159">**비정형 눈-응시 이동** Microsoft의 눈에는 고정에서 고정으로의 신속한 이동이 수행 됩니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-159">**Ragged eye-gaze movements** Our eyes perform rapid movements from fixation to fixation.</span></span> <span data-ttu-id="e5527-160">기록된 시선 움직임의 검색 경로를 바라보면 불규칙하다는 것을 알 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-160">If you look at scan paths of recorded eye movements, you can see that they look ragged.</span></span> <span data-ttu-id="e5527-161">*얼굴은 헤드-응시* 또는 *핸드 동작* 에 비해 신속 하 고 자발적으로 이동 합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-161">Your eyes move quickly and in spontaneous jumps in comparison to *head-gaze* or *hand motions*.</span></span>  

- <span data-ttu-id="e5527-162">**안정성 추적:** 눈이 새 조건에 맞게 조정 될 때 눈 추적 정확도는 약간의 변화를 덜 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-162">**Tracking reliability:** Eye tracking accuracy may degrade a little in changing light as your eyes adjust to the new conditions.</span></span>
<span data-ttu-id="e5527-163">이는 반드시 응용 프로그램 디자인에 영향을 주지는 않지만, 정확성은 2 ° 제한 이내에 있으므로 사용자가 다시 보정 해야 할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-163">While this shouldn't necessarily affect your application design, as the accuracy should be within the 2° limitation, it may be necessary for the user to calibrate again.</span></span> 


## <a name="design-recommendations"></a><span data-ttu-id="e5527-164">디자인 권장 사항</span><span class="sxs-lookup"><span data-stu-id="e5527-164">Design recommendations</span></span>
<span data-ttu-id="e5527-165">다음은 눈에 잘 맞는 입력에 대해 설명 된 장점과 문제에 따라 특정 디자인 권장 사항 목록입니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-165">The following is a list of specific design recommendations based on the described advantages and challenges for eye-gaze input:</span></span>

1. <span data-ttu-id="e5527-166">**눈동자-응시는 Head-응시와 동일 하지 않습니다.**</span><span class="sxs-lookup"><span data-stu-id="e5527-166">**Eye-gaze isn't the same as Head-gaze:**</span></span>
    - <span data-ttu-id="e5527-167">**입력 작업에 맞춰 신속 하 게 불규칙 하 게 진행 되는지 여부를 고려 합니다.** 보기의 필드에서 목표를 빠르게 선택 하는 것은 빠르게 진행 되지만 부드러운 입력 궤적 (예: drawing 또는 encircling 주석)을 필요로 하는 작업에는 적용 되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-167">**Consider whether fast yet ragged eye movements fit your input task:** While our fast and ragged eye movements are great at quickly selecting targets across our field of view, it's less applicable for tasks that require smooth input trajectories (for example, drawing or encircling annotations).</span></span> <span data-ttu-id="e5527-168">이 경우 손 또는 머리 가리키기가 더 나을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-168">In this case, hand or head pointing should be preferred.</span></span>
  
    - <span data-ttu-id="e5527-169">**사용자의 눈에 잘 들지 않는 항목 (예: 슬라이더 또는 커서)을 직접 연결 하지 않습니다.**</span><span class="sxs-lookup"><span data-stu-id="e5527-169">**Avoid attaching something directly to the user’s eye-gaze (for example, a slider or cursor).**</span></span>
<span data-ttu-id="e5527-170">커서를 사용 하면 예상 되는 눈 모양-응시 신호의 약간의 오프셋으로 인해 "fleeing cursor" 효과가 발생할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-170">With cursors, this may result in a "fleeing cursor" effect because of slight offsets in the projected eye-gaze signal.</span></span> <span data-ttu-id="e5527-171">슬라이더를 사용 하면 개체가 올바른 위치에 있는지 여부를 확인 하는 동안 눈에 따라 슬라이더를 제어 하는 double 역할과 충돌할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-171">With a slider, it can conflict with the double role of controlling the slider with your eyes while also wanting to check whether the object is at the correct location.</span></span> <span data-ttu-id="e5527-172">슬라이더의 예에서는 손 모양 제스처와 함께 눈동자-응시를 사용 하는 것이 더 적합 합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-172">For the example of the slider, it makes more sense to use eye-gaze in combination with hand gestures.</span></span> <span data-ttu-id="e5527-173">즉, 사용자가 신속 하 고 간편 하 게 여러 슬라이더 간을 전환 하 고, 손을 집기 하 고, 손가락을 잡고 인덱스 손가락을 잡고 이동할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-173">This means that the user could quickly and effortlessly switch among many sliders, raising up their hand and pinching their thumb and index finger to grab and move it.</span></span> <span data-ttu-id="e5527-174">손가락을 놓을 때 슬라이더의 이동이 중지 됩니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-174">When the pinch is released, the slider stops moving.</span></span> <span data-ttu-id="e5527-175">사용자는 이러한 사용자에 대 한 신호가 정확 하지 않을 경우, 특히 무시 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-175">Users could become overwhelmed and distracted, especially if the signal is imprecise for that user.</span></span> 
  
2. <span data-ttu-id="e5527-176">**눈동자를 다른 입력과 결합 합니다.** 시각 제스처, 음성 명령 또는 단추 누름과 같은 다른 입력과의 눈 추적 통합은 몇 가지 이점을 제공 합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-176">**Combine eye-gaze with other inputs:** The integration of eye tracking with other inputs, such as hand gestures, voice commands or button presses, provides several advantages:</span></span>
    - <span data-ttu-id="e5527-177">**무료 관찰 허용:** 사용자의 환경을 관찰 하는 것이 중요 하다는 것을 고려 하 여 사용자는 시각적 개체, 청각 등의 피드백이 나 작업을 트리거하지 않고도 사용자가 볼 수 있도록 하는 것이 중요 합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-177">**Allow for free observation:** Given that the main role of our eyes is to observe our environment, it's important that users are allowed to look around without triggering any (visual, auditory, and so on) feedback or actions.</span></span> 
    <span data-ttu-id="e5527-178">아이 추적을 다른 입력 컨트롤과 결합 하면 눈 추적 관찰 및 입력 제어 모드 간을 원활 하 게 전환할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-178">Combining eye tracking with another input control allows smooth transitioning between eye tracking observation and input control modes.</span></span>
  
    - <span data-ttu-id="e5527-179">**강력한 컨텍스트 공급자:** 음성 명령을 설명 하거나 손 모양 제스처를 사용 하 여 사용자가 확인 하는 위치와 위치에 대 한 정보를 사용 하 여 즉시 필드에서 입력을 원활 하 게 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-179">**Powerful context provider:** Using information about where and what the user is looking at while saying a voice command or using a hand gesture allows seamlessly channeling the input across the field-of-view.</span></span> <span data-ttu-id="e5527-180">예를 들어, 대상과 의도 한 대상을 확인 하 여 운용을 신속 하 고 신속 하 게 선택 하 여 장면 전체에 배치 하 _는 것을 말합니다._</span><span class="sxs-lookup"><span data-stu-id="e5527-180">For example: Say _"put that there"_ to quickly and fluently select and position a hologram across the scene by looking at a target and its intended destination.</span></span> 

    - <span data-ttu-id="e5527-181">**다중 모달 입력을 동기화 해야 합니다.** 긴 음성 명령 또는 핸드 제스처와 같이 보다 복잡 한 입력을 통해 신속한 시각 움직임을 결합 하면 추가 입력 명령이 완료 되 고 인식 되기 전에 사용자가 이미 계속 살펴볼 위험이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-181">**Need for synchronizing multimodal inputs:** Combining rapid eye movements with more complex inputs, such as long voice commands or hand gestures, bears the risk that the user already continues to look around before the extra input command is finished and recognized.</span></span> <span data-ttu-id="e5527-182">사용자 고유의 입력 컨트롤 (예: 사용자 지정 손 모양 제스처)을 만드는 경우이 입력 또는 대략적인 기간의 하기 시작 하면을 기록 하 여 사용자가 이전에 확인 한 것과 상관 관계를 지정 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-182">If you create your own input controls (for example, custom hand gestures), make sure to log the onset of this input or approximate duration to correlate it with what a user had looked at in the past.</span></span>
    
3. <span data-ttu-id="e5527-183">**눈 추적 입력에 대 한 미묘한 피드백:** 시스템이 의도 한 대로 작동 하지만 미묘한 상태로 유지 되어야 함을 나타내는 대상이 있는 경우 피드백을 제공 하는 것이 유용 합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-183">**Subtle feedback for eye tracking input:** It's useful to provide feedback when a target is looked at to indicate that the system is working as intended but should be kept subtle.</span></span> <span data-ttu-id="e5527-184">여기에는 느린 혼합, 시각적 강조 표시 또는 대상 크기를 약간 늘리지 않는 느린 동작 등의 기타 미묘한 대상 동작이 포함 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-184">This can include slowly blending in and out, visual highlights, or doing other subtle target behaviors, such as slow motions, such as slightly increasing the target size.</span></span> <span data-ttu-id="e5527-185">이는 사용자가 사용자의 현재 워크플로를 불필요 하 게 중단 하지 않고 대상에서 확인 하 고 있음을 시스템에서 올바르게 감지 했음을 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-185">This indicates that the system correctly detected that the user is looking at a target without unnecessarily interrupting the user’s current workflow.</span></span> 

4. <span data-ttu-id="e5527-186">**자연스럽 게 동작을 입력으로 적용 하지 마십시오.** 사용자가 특정 시각 이동 (응시 제스처)을 사용 하 여 응용 프로그램에서 작업을 트리거하지 않도록 합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-186">**Avoid enforcing unnatural eye movements as input:** Don't force users to use specific eye movements (gaze gestures) to trigger actions in your application.</span></span>

5. <span data-ttu-id="e5527-187">**Imprecision에 대 한 계정:** 사용자에 게 눈에 띄는 두 가지 유형의 imprecision (offset 및 지터)를 구분 합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-187">**Account for imprecisions:** We distinguish two types of imprecisions, which are noticeable to users: offset and jitter.</span></span> <span data-ttu-id="e5527-188">오프셋을 해결 하는 가장 쉬운 방법은 상호 작용할 수 있는 충분 한 대상을 제공 하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-188">The easiest way to address an offset is to provide sufficiently large targets to interact with.</span></span> <span data-ttu-id="e5527-189">2 ° 보다 큰 시각적 각도를 참조로 사용 하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-189">It's suggested that you use a visual angle greater than 2° as a reference.</span></span> <span data-ttu-id="e5527-190">예를 들어, arm을 확장 하는 경우 시각적 각도의 미리 보기는 약 2 °입니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-190">For instance, your thumbnail is about 2° in visual angle when you stretch out your arm.</span></span> <span data-ttu-id="e5527-191">이에 따라 다음과 같은 지침이 적용됩니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-191">This leads to the following guidance:</span></span>
    - <span data-ttu-id="e5527-192">사용자가 가장 작은 대상을 선택 하도록 강요 하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-192">Don't force users to select tiny targets.</span></span> <span data-ttu-id="e5527-193">대상이 충분히 크고 시스템이 잘 설계 된 경우, 사용자는 자신에 게 자신을 간편 하 게 설명 하 고 마법을 설명 합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-193">Research has shown that if targets are sufficiently large and system are designed well, users describe their interactions as effortless, and magical.</span></span> <span data-ttu-id="e5527-194">대상이 너무 작으면 조작 경험을 피곤하고 당황스러운 것으로 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-194">If targets become too small, users describe the experience as fatiguing and frustrating.</span></span>
  
<br>

<span data-ttu-id="e5527-195">이 페이지에서는 혼합 현실에서 입력으로 눈에 잘 이해할 수 있도록 하는 데 유용한 개요를 제공 했습니다.</span><span class="sxs-lookup"><span data-stu-id="e5527-195">This page provided you with a good overview to get you started understanding eye-gaze as an input in mixed reality.</span></span> <span data-ttu-id="e5527-196">개발을 시작 하려면 [에 대 한 자세한 정보를 확인](https://aka.ms/mrtk-eyes) [하세요.](../develop/native/gaze-in-directx.md)</span><span class="sxs-lookup"><span data-stu-id="e5527-196">To get started developing, check out our information on [eye-gaze in Unity](https://aka.ms/mrtk-eyes) and [eye-gaze in DirectX](../develop/native/gaze-in-directx.md).</span></span>


## <a name="see-also"></a><span data-ttu-id="e5527-197">참고 항목</span><span class="sxs-lookup"><span data-stu-id="e5527-197">See also</span></span>
* [<span data-ttu-id="e5527-198">편안함</span><span class="sxs-lookup"><span data-stu-id="e5527-198">Comfort</span></span>](comfort.md)
* [<span data-ttu-id="e5527-199">눈-DirectX에서 응시</span><span class="sxs-lookup"><span data-stu-id="e5527-199">Eye-gaze in DirectX</span></span>](../develop/native/gaze-in-directx.md)
* [<span data-ttu-id="e5527-200">눈동자-Unity에서 응시 (혼합 현실 도구 키트)</span><span class="sxs-lookup"><span data-stu-id="e5527-200">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="e5527-201">HoloLens 2의 시선 추적</span><span class="sxs-lookup"><span data-stu-id="e5527-201">Eye tracking on HoloLens 2</span></span>](eye-tracking.md)
* [<span data-ttu-id="e5527-202">응시 및 커밋</span><span class="sxs-lookup"><span data-stu-id="e5527-202">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="e5527-203">응시 및 유지</span><span class="sxs-lookup"><span data-stu-id="e5527-203">Gaze and dwell</span></span>](gaze-and-dwell.md)
* [<span data-ttu-id="e5527-204">음성 입력 </span><span class="sxs-lookup"><span data-stu-id="e5527-204">Voice input</span></span>](../out-of-scope/voice-design.md)