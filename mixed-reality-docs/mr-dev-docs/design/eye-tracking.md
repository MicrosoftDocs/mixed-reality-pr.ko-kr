---
title: 시선 추적
description: Holographic 환경에서 사용할 경우 HoloLens 2에 대 한 시각 추적 및 새로운 사용자 이해 수준을 알아봅니다.
author: sostel
ms.author: sostel
ms.date: 10/29/2019
ms.topic: article
keywords: 눈 추적, 혼합 현실, 입력, 눈에 응시, 보정, 혼합 현실 헤드셋, windows mixed reality 헤드셋, 가상 현실 헤드셋, HoloLens, MRTK, 혼합 현실 도구 키트, 의도, 작업
ms.openlocfilehash: a4010e5244539909d2b04cdb9e2044672d1decab
ms.sourcegitcommit: c0ba7d7bb57bb5dda65ee9019229b68c2ee7c267
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 05/19/2021
ms.locfileid: "110143239"
---
# <a name="eye-tracking-on-hololens-2"></a><span data-ttu-id="fd2f4-104">HoloLens 2의 시선 추적</span><span class="sxs-lookup"><span data-stu-id="fd2f4-104">Eye tracking on HoloLens 2</span></span>

![MRTK의 아이 추적 데모](images/mrtk_et_scenemenu.jpg)

<span data-ttu-id="fd2f4-106">HoloLens 2를 사용 하면 개발자에 게 사용자가 보고 있는 항목에 대 한 정보를 사용할 수 있는 기능을 제공 하 여 holographic 환경 내에서 새로운 수준의 컨텍스트 및 인간 이해를 허용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-106">HoloLens 2 allows for a new level of context and human understanding within the holographic experience by providing developers with the ability to use information about what the user is looking at.</span></span> <span data-ttu-id="fd2f4-107">이 페이지에서는 개발자가 다양 한 사용 사례에 대 한 눈 추적을 활용 하는 방법 및 눈에 잘 맞는 사용자 상호 작용을 디자인할 때 검색할 사항을 설명 합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-107">This page explains how developers can benefit from eye tracking for various use cases, and what to look for when designing eye-gaze-based user interactions.</span></span> 

<span data-ttu-id="fd2f4-108">아이 추적 API는 사용자의 개인 정보를 염두에 두면 서 식별 가능한 정보, 특히 생체 인식을 피할 수 있도록 설계 되었습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-108">Eye tracking API has been designed with a user’s privacy in mind, avoiding passing any identifiable information, particularly any biometrics.</span></span> <span data-ttu-id="fd2f4-109">아이 추적 지원 응용 프로그램의 경우 사용자는 눈동자 추적 정보를 사용할 수 있는 권한을 앱에 부여 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-109">For eye-tracking capable applications, the user needs to grant app permission to use eye tracking information.</span></span>

### <a name="device-support"></a><span data-ttu-id="fd2f4-110">디바이스 지원</span><span class="sxs-lookup"><span data-stu-id="fd2f4-110">Device support</span></span>

<table>
<colgroup>
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
    <col width="25%" />
</colgroup>
<tr>
     <td><span data-ttu-id="fd2f4-111"><strong>기능</strong></span><span class="sxs-lookup"><span data-stu-id="fd2f4-111"><strong>Feature</strong></span></span></td>
     <td><span data-ttu-id="fd2f4-112"><a href="/hololens/hololens1-hardware"><strong>HoloLens(1세대)</strong></a></span><span class="sxs-lookup"><span data-stu-id="fd2f4-112"><a href="/hololens/hololens1-hardware"><strong>HoloLens (1st gen)</strong></a></span></span></td>
     <td><span data-ttu-id="fd2f4-113"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span><span class="sxs-lookup"><span data-stu-id="fd2f4-113"><a href="https://docs.microsoft.com/hololens/hololens2-hardware"><strong>HoloLens 2</strong></span></span></td>
     <td><span data-ttu-id="fd2f4-114"><a href="../discover/immersive-headset-hardware-details.md"><strong>몰입형 헤드셋</strong></a></span><span class="sxs-lookup"><span data-stu-id="fd2f4-114"><a href="../discover/immersive-headset-hardware-details.md"><strong>Immersive headsets</strong></a></span></span></td>
</tr>
<tr>
     <td><span data-ttu-id="fd2f4-115">눈-응시</span><span class="sxs-lookup"><span data-stu-id="fd2f4-115">Eye-gaze</span></span></td>
     <td>❌</td>
     <td><span data-ttu-id="fd2f4-116">✔️</span><span class="sxs-lookup"><span data-stu-id="fd2f4-116">✔️</span></span></td>
     <td>❌</td>
</tr>
</table>

<br>

## <a name="head-and-eye-tracking-design-concepts-demo"></a><span data-ttu-id="fd2f4-117">헤드 및 눈 추적 디자인 개념 데모</span><span class="sxs-lookup"><span data-stu-id="fd2f4-117">Head and eye tracking design concepts demo</span></span>

<span data-ttu-id="fd2f4-118">요약 및 눈 추적 디자인 개념이 작동 하는 것을 확인 하려는 경우 아래 [Holograms 추적 및 눈동자]() 추적 비디오 데모를 확인 하세요.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-118">If you'd like to see Head and Eye Tracking design concepts in action, check out our [Designing Holograms - Head Tracking and Eye Tracking]() video demo below.</span></span> <span data-ttu-id="fd2f4-119">완료 되 면 특정 항목에 대 한 자세한 정보를 계속 확인할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-119">When you've finished, continue on for a more detailed dive into specific topics.</span></span>

> [!VIDEO https://channel9.msdn.com/Shows/Docs-Mixed-Reality/Microsofts-Designing-Holograms-Head-Tracking-and-Eye-Tracking-Chapter/player]

## <a name="calibration"></a><span data-ttu-id="fd2f4-120">보정</span><span class="sxs-lookup"><span data-stu-id="fd2f4-120">Calibration</span></span> 

<span data-ttu-id="fd2f4-121">눈 추적을 정확 하 게 수행 하려면 각 사용자가 holographic 대상 집합을 확인 해야 하는 [눈 추적 사용자 보정](/hololens/hololens-calibration) 을 통과 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-121">For eye tracking to work accurately, each user is required to go through an [eye tracking user calibration](/hololens/hololens-calibration) for which the user has to look at a set of holographic targets.</span></span> <span data-ttu-id="fd2f4-122">이를 통해 장치는 사용자에 게 더 편안 하 고 높은 품질의 시청 환경을 제공 하 고 동시에 정확한 시각 추적을 보장 합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-122">This allows the device to adjust the system for a more comfortable and higher quality viewing experience for the user and to ensure accurate eye tracking at the same time.</span></span> 

<span data-ttu-id="fd2f4-123">시각 추적은 대부분의 사용자에 게 작동 하지만 사용자가 성공적으로 보정할 수 없는 드문 경우도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-123">Eye tracking should work for most users, but there are rare cases in which a user can't calibrate successfully.</span></span> <span data-ttu-id="fd2f4-124">보정은 다음을 비롯 한 다양 한 이유로 실패할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-124">Calibration might fail for various reasons, including but not limited to:</span></span> 
* <span data-ttu-id="fd2f4-125">사용자가 이전에 보정 프로세스를 옵트아웃 했음</span><span class="sxs-lookup"><span data-stu-id="fd2f4-125">The user previously opted out of the calibration process</span></span>
* <span data-ttu-id="fd2f4-126">사용자가 무시 하 고 보정 대상을 팔 로우 하지 않았습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-126">The user got distracted and didn't follow the calibration targets</span></span>
* <span data-ttu-id="fd2f4-127">사용자에 게 시스템에서 아직 지원 하지 않는 특정 유형의 연락처 lenses 및가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-127">The user has certain types of contact lenses and glasses, which the system doesn't yet support</span></span> 
* <span data-ttu-id="fd2f4-128">사용자에게 특정 눈 병과, 눈 상태 또는 시스템이 아직 지원하지 않는 안과가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-128">The user has certain eye physiology, eye conditions or had eye surgery, which the system doesn't yet support</span></span>  
* <span data-ttu-id="fd2f4-129">HoloLens 바이저 또는 안경의 스미징, 눈 앞의 머리로 인한 집중적인 직접 스래핑 및 폐색과 같은 안정적인 시선 추적을 방해하는 외부 요소</span><span class="sxs-lookup"><span data-stu-id="fd2f4-129">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight, and occlusions due to hair in front of the eyes</span></span>

<span data-ttu-id="fd2f4-130">개발자는 시선 추적 데이터를 사용할 수 없는 사용자(성공적으로 보정할 수 없는 사용자)에 대해 적절한 지원을 제공해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-130">Developers should make sure to provide adequate support for users for whom eye tracking data may not be available (who aren't able to calibrate successfully).</span></span> <span data-ttu-id="fd2f4-131">대체 솔루션에 대한 권장 사항은 이 페이지 아래쪽의 섹션에 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-131">We have provided recommendations for fallback solutions in the section at the bottom of this page.</span></span> 

<span data-ttu-id="fd2f4-132">보정 및 원활한 환경을 보장하는 방법에 대해 자세히 알아보려면 [시선 추적 사용자 보정](/hololens/hololens-calibration) 페이지를 확인하세요.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-132">To learn more about the calibration and about how to ensure a smooth experience, check our [eye tracking user calibration](/hololens/hololens-calibration) page.</span></span>

<br>

## <a name="available-eye-tracking-data"></a><span data-ttu-id="fd2f4-133">사용 가능한 시선 추적 데이터</span><span class="sxs-lookup"><span data-stu-id="fd2f4-133">Available eye tracking data</span></span>

<span data-ttu-id="fd2f4-134">시선 응시 입력에 대한 특정 사용 사례에 대해 자세히 알아보기 전에 HoloLens 2 시선 추적 [API에서](/uwp/api/windows.perception.people.eyespose) 제공하는 기능을 간략하게 설명하려고 합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-134">Before going into detail about specific use cases for eye-gaze input, we want to briefly point out the capabilities that the HoloLens 2 [Eye Tracking API](/uwp/api/windows.perception.people.eyespose) provides.</span></span> <span data-ttu-id="fd2f4-135">개발자는 약 _30FPS(30Hz)에서_ 단일 시선 응시 광선(응시 원점 및 방향)에 액세스할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-135">Developers get access to a single eye-gaze ray (gaze origin and direction) at approximately _30 FPS (30 Hz)_.</span></span>
<span data-ttu-id="fd2f4-136">시선 추적 데이터에 액세스하는 방법에 대한 자세한 내용은 [DirectX에서 시선 응시를 사용하고 Unity에서 시선 응시를](../develop/native/gaze-in-directx.md) 사용하기 위한 개발자 가이드를 [참조하세요.](https://aka.ms/mrtk-eyes)</span><span class="sxs-lookup"><span data-stu-id="fd2f4-136">For more detailed information about how to access eye tracking data, refer to our developer guides for using [eye-gaze in DirectX](../develop/native/gaze-in-directx.md) and [eye-gaze in Unity](https://aka.ms/mrtk-eyes).</span></span>

<span data-ttu-id="fd2f4-137">예측된 시선 응시는 실제 대상 주위의 시각적 각도에서 약 1.5도 이내입니다(아래 그림 참조).</span><span class="sxs-lookup"><span data-stu-id="fd2f4-137">The predicted eye-gaze is approximately within 1.5 degrees in visual angle around the actual target (see the illustration below).</span></span> <span data-ttu-id="fd2f4-138">약간의 부정확성이 예상되면 개발자는 이 하한 값을 중심으로 약간의 여백을 계획해야 합니다(예: 2.0-3.0도는 훨씬 더 편안하게 환경을 생성할 수 있음).</span><span class="sxs-lookup"><span data-stu-id="fd2f4-138">As slight imprecisions are expected, developers should plan for some margin around this lower-bound value (for example, 2.0-3.0 degrees may result in a much more comfortable experience).</span></span> <span data-ttu-id="fd2f4-139">아래에서는 작은 대상 선택을 해결하는 방법을 자세히 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-139">We'll discuss how to address the selection of small targets in more detail below.</span></span> <span data-ttu-id="fd2f4-140">시선 추적이 정확히 작동하려면 각 사용자가 시선 추적 사용자 보정을 진행해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-140">For eye tracking to work accurately, each user is required to go through an eye tracking user calibration.</span></span> 

<span data-ttu-id="fd2f4-141">![2m 거리에서 최적 대상 크기](images/gazetargeting-size-1000px.jpg)</span><span class="sxs-lookup"><span data-stu-id="fd2f4-141">![Optimal target size at 2 meter distance](images/gazetargeting-size-1000px.jpg)</span></span><br>
<span data-ttu-id="fd2f4-142">*2미터 거리에 있는 최적 대상 크기*</span><span class="sxs-lookup"><span data-stu-id="fd2f4-142">*Optimal target size at a 2-meter distance*</span></span>

<br>

## <a name="use-cases"></a><span data-ttu-id="fd2f4-143">사용 사례</span><span class="sxs-lookup"><span data-stu-id="fd2f4-143">Use cases</span></span>

<span data-ttu-id="fd2f4-144">시선 추적을 사용하여 애플리케이션에서는 사용자가 실시간으로 보는 곳을 추적할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-144">Eye tracking enables applications to track where the user is looking in real time.</span></span> <span data-ttu-id="fd2f4-145">다음 사용 사례에서는 혼합 현실의 HoloLens 2 대한 시선 추적에서 가능한 몇 가지 상호 작용에 대해 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-145">The following use cases describe some interactions that are possible with eye tracking on HoloLens 2 in mixed reality.</span></span>
<span data-ttu-id="fd2f4-146">이러한 사용 사례는 아직 Holographic Shell 환경(즉, HoloLens 2 시작할 때 표시되는 인터페이스)의 일부가 아닙니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-146">These use cases aren't yet part of the Holographic Shell experience (that is, the interface that you see when you start up your HoloLens 2).</span></span>
<span data-ttu-id="fd2f4-147">[혼합 현실 도구 키트](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html)에서이 중 일부를 사용해 볼 수 있습니다 .이 도구 키트는 빠르고 간편 하 게 지원 되는 대상 선택 항목과 같은 눈 추적 사용에 대 한 몇 가지 흥미롭고 강력한 예제를 제공 하 고 사용자가 보는 내용에 따라 자동으로 텍스트를 스크롤합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-147">You can try some of them in the [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html), which provides several interesting and powerful examples for using eye tracking, such as quick and effortless eye-supported target selections, and automatically scrolling through text based on what the user looks at.</span></span> 

### <a name="user-intent"></a><span data-ttu-id="fd2f4-148">사용자 의도</span><span class="sxs-lookup"><span data-stu-id="fd2f4-148">User intent</span></span>

<span data-ttu-id="fd2f4-149">사용자가 확인 하는 위치와 위치에 대 한 정보는 음성, 실습 및 컨트롤러와 같은 **다른 입력을 위한 강력한 컨텍스트** 를 제공 합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-149">Information about where and what a user looks at provides a powerful **context for other inputs**, such as voice, hands, and controllers.</span></span>
<span data-ttu-id="fd2f4-150">이러한 컨텍스트를 다양한 작업에서 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-150">This can be used for various tasks.</span></span>
<span data-ttu-id="fd2f4-151">예를 들어,이는 홀로그램을 확인 하  고 *"선택"* ( [응시 및 커밋](gaze-and-commit.md)) 또는 "준비 중 ... *"* 이라고 하 고 사용자가 홀로그램을 배치할 위치를 확인 하 고, *"... "*.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-151">For example, this can range from quickly and effortlessly **targeting** across the scene by looking at a hologram and saying *"select"* (also see [gaze and commit](gaze-and-commit.md)) or *"put this..."*, then looking over to where the user wants to place the hologram and say *"...there"*.</span></span> <span data-ttu-id="fd2f4-152">이에 대한 예는 [Mixed Reality Toolkit - 시선 지원 대상 선택](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) 및 [Mixed Reality Toolkit - 시선 지원 대상 위치 지정](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html)에서 찾을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-152">Examples for this can be found in [Mixed Reality Toolkit - Eye-supported Target Selection](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_TargetSelection.html) and [Mixed Reality Toolkit - Eye-supported Target Positioning](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Positioning.html).</span></span>

<span data-ttu-id="fd2f4-153">또한 사용자 의도에 대 한 예제에는 사용자가 합의서 등 가상 에이전트 및 대화형 holograms 참여를 개선 하기 위해 확인 하는 내용에 대 한 정보가 포함 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-153">Additionally, an example for user intent might include using information about what users look at to enhance engagement with embodied virtual agents and interactive holograms.</span></span> <span data-ttu-id="fd2f4-154">예를 들어 가상 에이전트는 현재 표시 되는 내용에 따라 사용 가능한 옵션과 해당 동작을 조정할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-154">For instance, virtual agents might adapt available options and their behavior, based on currently viewed content.</span></span> 

### <a name="implicit-actions"></a><span data-ttu-id="fd2f4-155">암시적 작업</span><span class="sxs-lookup"><span data-stu-id="fd2f4-155">Implicit actions</span></span>

<span data-ttu-id="fd2f4-156">암시적 작업의 범주는 사용자 의도와 밀접하게 관련되어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-156">The category of implicit actions closely relates to user intent.</span></span>
<span data-ttu-id="fd2f4-157">Holograms 또는 사용자 인터페이스 요소는 사용자가 시스템과 상호 작용 하는 것 처럼 보이지만 시스템 및 사용자가 동기화 되는 것 처럼 보일 수 있는 instinctual 방식으로 반응 합니다. 한 가지 예는 사용자가 긴 텍스트를 읽을 수 있는 **눈에 잘 맞는 자동 스크롤** 입니다. 사용자가 텍스트 상자 아래쪽에 있으면 손가락을 떼지 않고 사용자를 읽기 흐름으로 유지할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-157">The idea is that holograms or user interface elements react in an instinctual way that may not even feel like the user is interacting with the system at all, but rather that the system and the user are in sync. One example is **eye-gaze-based auto scroll** where the user can read a long text, which automatically starts scrolling once the user gets to the bottom of the textbox to keep the user in the flow of reading, without lifting a finger.</span></span>  
<span data-ttu-id="fd2f4-158">이에 대 한 주요 측면은 스크롤 속도가 사용자의 읽기 속도에 적응 하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-158">A key aspect of this is that the scrolling speed adapts to the reading speed of the user.</span></span>
<span data-ttu-id="fd2f4-159">또 다른 예로, 사용자가 중심으로 하는 것과 정확히 일치 하는 것을 느낄 수 있는 **눈에 잘 지 원하는 확대/축소 및 이동** 이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-159">Another example is **eye-supported zoom and pan** where the user can feel like diving exactly toward what he or she's focused on.</span></span> <span data-ttu-id="fd2f4-160">확대/축소 속도를 트리거하거나 제어 하는 것은 음성 또는 직접 입력을 통해 제어할 수 있습니다 .이는 사용자에 게 불필요 한 제어를 제공 하는 데 중요 합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-160">Triggering and controlling zoom speed can be controlled by voice or hand input, which is important for providing the user with the feeling of control while avoiding being overwhelmed.</span></span> <span data-ttu-id="fd2f4-161">이러한 디자인 고려 사항은 아래에서 자세히 설명 합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-161">We'll talk about these design considerations in more detail below.</span></span> <span data-ttu-id="fd2f4-162">확대하면 사용자는 거리 과정을 원활하게 따라 시선 응시를 사용하여 자신의 지역을 탐색할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-162">Once zoomed in, the user can smoothly follow, for example, the course of a street to explore his or her neighborhood by using their eye-gaze.</span></span>
<span data-ttu-id="fd2f4-163">이러한 유형의 상호 작용을 나타내는 데모 예제는 [Mixed Reality Toolkit - 시선 지원 탐색](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) 샘플에서 찾을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-163">Demo examples for these types of interactions can be found in the [Mixed Reality Toolkit - Eye-supported Navigation](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Navigation.html) sample.</span></span>

<span data-ttu-id="fd2f4-164">_암시적 작업에_ 대한 다른 사용 사례는 다음과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-164">Other use cases for _implicit actions_ may include:</span></span>
- <span data-ttu-id="fd2f4-165">**스마트 알림:** 보고 있는 위치에 알림이 팝업되는 것이 불편해 보이는 경우는 언제인가요?</span><span class="sxs-lookup"><span data-stu-id="fd2f4-165">**Smart notifications:** Ever get annoyed by notifications popping up right where you're looking?</span></span> <span data-ttu-id="fd2f4-166">사용자가 주의를 기울이는 것을 고려하여 사용자가 현재 주의를 기울이는 위치에서 알림을 오프셋하여 이 환경을 더 잘 만들 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-166">Taking into account what a user is paying attention to, you can make this experience better by offsetting notifications from where the user is currently gazing.</span></span> <span data-ttu-id="fd2f4-167">이렇게 하면 사용자의 읽기가 완료되면 방해가 제한되고 자동으로 해제됩니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-167">This limits distractions and automatically dismisses them once the user is finished reading.</span></span> 
- <span data-ttu-id="fd2f4-168">**들여쓰기 홀로그램:** 홀로그램은 잡히면 은소하게 반응합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-168">**Attentive holograms:** Holograms that subtly react when being gazed upon.</span></span> <span data-ttu-id="fd2f4-169">이 범위는 약간 후광이 있는 UI 요소, 느리게 피어링하는 꽃에서 사용자를 다시 보기 시작하고 꼬리를 흔드는 가상 개까지 다양합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-169">This can range from slightly glowing UI elements, a slowly blooming flower to a virtual dog starting to look back at the user and wagging its tail.</span></span> <span data-ttu-id="fd2f4-170">이러한 상호 작용은 애플리케이션에서 연결성 및 만족도에 대한 흥미로운 의미를 제공할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-170">This interaction might provide an interesting sense of connectivity and satisfaction in your application.</span></span>

### <a name="attention-tracking"></a><span data-ttu-id="fd2f4-171">주의 추적</span><span class="sxs-lookup"><span data-stu-id="fd2f4-171">Attention tracking</span></span>

<span data-ttu-id="fd2f4-172">사용자가 보는 위치 또는 내용에 대한 정보는 매우 강력한 도구일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-172">Information on where or what users look at can be an immensely powerful tool.</span></span> <span data-ttu-id="fd2f4-173">디자인의 유용성을 평가하고 워크플로의 문제를 식별하여 더 효율적으로 만들 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-173">It can help assess usability of designs and identify problems in workflows to make them more efficient.</span></span>
<span data-ttu-id="fd2f4-174">시선 추적 시각화 및 분석은 다양한 애플리케이션 영역에서 일반적인 사례입니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-174">Eye tracking visualization and analytics are a common practice in various application areas.</span></span> <span data-ttu-id="fd2f4-175">HoloLens 2 통해 3D 홀로그램을 실제 컨텍스트에 배치하고 그에 따라 평가할 수 있으므로 이 이해를 위한 새로운 차원을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-175">With HoloLens 2, we provide a new dimension to this understanding as 3D holograms can be placed in real-world contexts and assessed accordingly.</span></span> <span data-ttu-id="fd2f4-176">[Mixed Reality 도구 키트는](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) 시선 추적 데이터를 로깅 및 로드하고 시각화하는 방법에 대한 기본 예제를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-176">The [Mixed Reality Toolkit](https://microsoft.github.io/MixedRealityToolkit-Unity/Documentation/EyeTracking/EyeTracking_Main.html) provides basic examples for logging and loading eye tracking data and how to visualize them.</span></span>
<span data-ttu-id="fd2f4-177">Microsoft는 사용자가 시선 추적 정보를 사용하는 방법에 대해 정보를 제공하고 투명한 환경을 갖추도록 하면서 혁신을 촉진하는 데 최선을 다하고 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-177">Microsoft is dedicated to facilitating innovation while ensuring that users have an informed and transparent experience with how their eye tracking information is used.</span></span>  <span data-ttu-id="fd2f4-178">개발자 및 UX 팀과 협력하여 타사에 대한 지침을 제공하여 환경이 사용자를 중심으로 배치되도록 할 것입니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-178">We'll work with our developers and UX teams to provide guidance for third parties to ensure that experiences are centered around the user.</span></span>  

<span data-ttu-id="fd2f4-179">이 영역의 다른 응용 분야로 다음이 포함될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-179">Other applications in this area may include:</span></span> 
-   <span data-ttu-id="fd2f4-180">**원격 시선 응시 시각화:** 원격 시선 응시 시각화: 원격 협력자가 보고 있는 내용을 시각화하여 즉각적인 피드백을 제공하고 보다 정확한 정보 처리를 용이하게 할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-180">**Remote eye-gaze visualization:** Remote eye-gaze visualizations: Visualize what remote collaborators are looking at, to be able to provide immediate feedback and facilitate more accurate information processing.</span></span>
-   <span data-ttu-id="fd2f4-181">**사용자 연구 연구:** 주의 추적을 사용 하면 사용자가 방해 하지 않고 자연 스러운 환경을 통해 사용자의 instinctual 상호 작용을 개선 하는 방법에 대 한 자세한 정보를 얻을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-181">**User research studies:** Attention tracking can help researchers get more insights into how users perceive and engage with the natural environment, without interfering, to design more instinctual human-computer-interactions.</span></span> <span data-ttu-id="fd2f4-182">눈 추적은 연구에서 참가자가 직접 연락 하지 않는 정보를 제공할 수 있으며, 그렇지 않은 경우에는 연구원에 의해 쉽게 누락 될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-182">Eye tracking can provide information that is not directly articulated by participants in the study, which otherwise might be easily missed by the researcher.</span></span> 
-   <span data-ttu-id="fd2f4-183">**교육 및 성능 모니터링:** 실행 흐름에서 병목 상태를 보다 효과적으로 식별 하 여 작업 실행을 연습 하 고 최적화 합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-183">**Training and performance monitoring:** Practice and optimize the execution of tasks by identifying bottlenecks more effectively in the execution flow.</span></span> <span data-ttu-id="fd2f4-184">눈 추적은 자연 스러운 실시간 및 목표 정보를 제공 하 여 작업 공간에서 학습, 생산성 및 안전을 향상 시킬 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-184">Eye tracking can provide natural, real-time, and objective information to help improve training, productivity, and safety in the workplace.</span></span> 
-   <span data-ttu-id="fd2f4-185">**디자인 평가, 마케팅 및 소비자 연구:** 아이 추적을 사용 하면 상용 회사에서 실제 환경에서 마케팅 및 소비자 연구를 수행 하거나 제품 또는 공간 디자인을 개선 하기 위해 사용자의 주의가 필요한 사항을 분석할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-185">**Design evaluations, marketing, and consumer research:** Eye tracking enables commercial companies to perform marketing and consumer studies in real-world environments or analyze what captures a user’s attention to improve product or space design.</span></span> 

### <a name="other-use-cases"></a><span data-ttu-id="fd2f4-186">기타 사용 사례</span><span class="sxs-lookup"><span data-stu-id="fd2f4-186">Other use cases</span></span>

- <span data-ttu-id="fd2f4-187">**게임:** 슈퍼 능력을 원하는 가요?</span><span class="sxs-lookup"><span data-stu-id="fd2f4-187">**Gaming:** Ever wanted to have superpowers?</span></span> <span data-ttu-id="fd2f4-188">여기서 그 기회를 얻을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-188">Here's your chance!</span></span> <span data-ttu-id="fd2f4-189">Holograms에서 바랄 levitate 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-189">You can levitate holograms by staring at them.</span></span> <span data-ttu-id="fd2f4-190">눈에서 레이저 빔를 체험해 보세요. [RoboRaid에서 HoloLens 2에 대해](https://www.microsoft.com/p/roboraid/9nblggh5fv3j)사용해 보세요.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-190">Shoot laser beams from your eyes - try it out in [RoboRaid for HoloLens 2](https://www.microsoft.com/p/roboraid/9nblggh5fv3j).</span></span>
<span data-ttu-id="fd2f4-191">적을 돌로 설정 하거나 고정 합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-191">Turn enemies into stone or freeze them.</span></span> <span data-ttu-id="fd2f4-192">X-광선을 사용해서 건물을 투시하세요.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-192">Use your x-ray vision to explore buildings.</span></span> <span data-ttu-id="fd2f4-193">상상하는 만큼 이루어집니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-193">Your imagination is the limit!</span></span>
<span data-ttu-id="fd2f4-194">사용자를 과도 하 게 확인 하는 것이 좋습니다. 자세한 내용은 눈에 잘 맞는 [입력 디자인 지침](eye-gaze-interaction.md)을 참조 하세요.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-194">Beware of not overwhelming the user though - to find out more, check out our [eye-gaze-based input design guidelines](eye-gaze-interaction.md).</span></span>

- <span data-ttu-id="fd2f4-195">**표현 아바타:** 눈 추적은 라이브 눈 추적 데이터를 사용 하 여 사용자가 보고 있는 항목을 나타내는 아바타의 눈에 애니메이션 효과를 주는 3D 아바타 더 많은 표현을 지원 합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-195">**Expressive avatars:** Eye tracking aids in more expressive 3D avatars by using live eye tracking data to animate the avatar's eyes that indicate what the user is looking at.</span></span> 

- <span data-ttu-id="fd2f4-196">**텍스트 입력:** 눈에 잘 드는 텍스트 입력에 대 한 대체 방법으로 눈 추적을 사용할 수 있습니다. 특히 음성 또는 손을 사용 하기 불편 한 경우입니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-196">**Text entry:** Eye tracking can be used as an alternative for low-effort text entry, especially when speech or hands are inconvenient to use.</span></span> 

<br>

## <a name="using-eye-gaze-for-interaction"></a><span data-ttu-id="fd2f4-197">상호 작용을 위해 눈동자 사용-응시</span><span class="sxs-lookup"><span data-stu-id="fd2f4-197">Using eye-gaze for interaction</span></span>

<span data-ttu-id="fd2f4-198">빠른 이동 대상 지정을 활용 하는 상호 작용을 빌드하는 것은 어려울 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-198">Building an interaction that takes advantage of fast-moving eye targeting can be challenging.</span></span>
<span data-ttu-id="fd2f4-199">한편, 눈은 눈에 눈길을 사용 하는 방법에 주의 해야 합니다. 그렇지 않으면 사용자가 경험을 과도 하 게 경험해 볼 수 있기 때문입니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-199">On the one hand, the eyes move so fast that you need to be careful on how to use eye-gaze input, because otherwise users may find the experience overwhelming or distracting.</span></span> <span data-ttu-id="fd2f4-200">반면 사용자를 흥미 하는 진정한 마법 환경을 만들 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-200">On the other hand, you can also create truly magical experiences that will excite your users!</span></span> <span data-ttu-id="fd2f4-201">도움을 주려면 [상호 작용에 대한 시선 응시에](eye-gaze-interaction.md)대한 주요 이점, 과제 및 디자인 권장 사항의 개요를 확인하세요.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-201">To help you, check out our overview of key advantages, challenges, and design recommendations for [eye-gaze for interaction](eye-gaze-interaction.md).</span></span> 
 
## <a name="fallback-solutions-when-eye-tracking-isnt-available"></a><span data-ttu-id="fd2f4-202">시선 추적을 사용할 수 없는 경우의 대체 솔루션</span><span class="sxs-lookup"><span data-stu-id="fd2f4-202">Fallback solutions when eye tracking isn't available</span></span>

<span data-ttu-id="fd2f4-203">드문 경우로 시선 추적 데이터를 사용할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-203">In rare cases, eye tracking data might not be available.</span></span>
<span data-ttu-id="fd2f4-204">가장 일반적인 이유가 아래에 나열되어 있기 때문일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-204">This can be because of different reasons from which the most common are listed below:</span></span>
* <span data-ttu-id="fd2f4-205">시스템에서 사용자 를 [보정하지](/hololens/hololens-calibration)못했습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-205">The system failed to [calibrate the user](/hololens/hololens-calibration).</span></span>
* <span data-ttu-id="fd2f4-206">사용자가 [보정](/hololens/hololens-calibration)을 건너뛰습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-206">The user skipped the [calibration](/hololens/hololens-calibration).</span></span>   
* <span data-ttu-id="fd2f4-207">사용자가 보정되었지만 시선 추적 데이터를 사용할 수 있는 권한을 앱에 부여하지 않기로 결정했습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-207">The user is calibrated, but decided to not give permission to your app to use their eye tracking data.</span></span>    
* <span data-ttu-id="fd2f4-208">사용자에게 시스템이 아직 지원하지 않는 고유한 안경 또는 일부 시선 상태가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-208">The user has unique eyeglasses or some eye condition that the system doesn't yet support.</span></span> 
* <span data-ttu-id="fd2f4-209">HoloLens 바이저 또는 안경의 스미징, 눈 앞의 머리로 인한 집중적인 직접 스래핑 및 폐색과 같은 안정적인 시선 추적을 방해하는 외부 요소입니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-209">External factors inhibiting reliable eye tracking such as smudges on the HoloLens visor or eyeglasses, intense direct sunlight, and occlusions because of hair in front of the eyes.</span></span>

<span data-ttu-id="fd2f4-210">개발자는 이러한 사용자에 대한 적절한 대체 지원이 있는지 확인해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-210">Developers should ensure that there's appropriate fallback support for these users.</span></span> <span data-ttu-id="fd2f4-211">[DirectX의 시선 추적](../develop/native/gaze-in-directx.md#fallback-when-eye-tracking-isnt-available) 페이지에서 시선 추적 데이터를 사용할 수 있는지 여부를 감지하는 데 필요한 API에 대해 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-211">On the [Eye Tracking in DirectX](../develop/native/gaze-in-directx.md#fallback-when-eye-tracking-isnt-available) page, we explain the APIs required to detect whether eye tracking data is available.</span></span> 

<span data-ttu-id="fd2f4-212">일부 사용자는 시선 추적 데이터에 대한 액세스 권한을 취소하기로 결정했지만 시선 추적 데이터에 대한 액세스를 제공하지 않는 개인 정보 보호에 대한 유추 사용자 환경의 장단점으로도 문제가 되지 않을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-212">While some users may have consciously decided to revoke,  access to their eye tracking data and are ok with the trade-off of an inferior user experience to the privacy of not providing access to their eye tracking data, in some cases this may be unintentional.</span></span> <span data-ttu-id="fd2f4-213">앱에서 시선 추적을 사용하고 이 부분이 환경의 중요한 부분인 경우 사용자에게 명확하게 전달하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-213">If your app uses eye tracking, and this is an important part of the experience, we recommend clearly communicating this to the user.</span></span>   

<span data-ttu-id="fd2f4-214">애플리케이션의 모든 잠재력을 경험하기 위해 애플리케이션에 시선 추적이 중요한 이유(일부 향상된 기능도 나열)를 사용자에게 알리면 사용자가 포기할 내용을 더 잘 이해할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-214">Kindly informing the user why eye tracking is critical for your application (maybe even listing some enhanced features) to experience the full potential of your application, can help the user to better understand what they're giving up.</span></span> <span data-ttu-id="fd2f4-215">사용자가 위 검사에 따라 시선 추적이 작동하지 않는 이유를 식별하고 잠재적인 문제를 신속하게 해결하기 위한 몇 가지 제안을 제공하도록 도와 주세요.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-215">Help the user identify why eye tracking may not be working (based on the above checks) and offer some suggestions to quickly troubleshoot potential issues.</span></span> 

<span data-ttu-id="fd2f4-216">예를 들어 시스템에서 눈 추적을 지원함을 감지할 수 있는 경우 사용자가 보정 되 고 사용자에 게는 해당 사용 권한도 부여 된 경우에도 사용자가 보정 하거나 폐색 되는 눈동자와 같은 일부 다른 문제를 가리킬 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-216">For example, if you can detect that the system supports eye tracking, the user is calibrated and has even given their permission, yet no eye tracking data is received, then this may point to some other issues such as smudges or the eyes being occluded.</span></span> 

<span data-ttu-id="fd2f4-217">자주 발생 하지 않는 사용자의 경우는 거의 없습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-217">There are rare cases of users for whom eye tracking may not work.</span></span> <span data-ttu-id="fd2f4-218">따라서 앱에서 눈 추적을 사용 하도록 설정 하는 경우 미리 알림을 해제 하거나 사용 하지 않도록 설정 하 여 respectful 합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-218">Hence, please be respectful of that by allowing to dismiss or even disable reminders for enabling eye tracking in your app.</span></span>

### <a name="fall-back-for-apps-using-eye-gaze-as-a-primary-input-pointer"></a><span data-ttu-id="fd2f4-219">기본 입력 포인터로 눈동자-응시를 사용 하 여 앱을 대체 합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-219">Fall back for apps using eye-gaze as a primary input pointer</span></span>

<span data-ttu-id="fd2f4-220">앱에서 포인터 입력으로 눈에 holograms를 사용 하 여 장면에서의 작업을 빠르게 선택 하 고, 아이 추적 데이터를 사용할 수 없는 경우 헤드-응시로 대체 하 여 헤드-응시 커서를 표시 하기 시작 하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-220">If your app uses eye-gaze as a pointer input to quickly select holograms across the scene, yet eye tracking data is unavailable, we recommend falling back to head-gaze and start showing the head-gaze cursor.</span></span> <span data-ttu-id="fd2f4-221">스위치를 사용할지 여부를 결정 하는 데 시간 제한 (예: 500 – 1500 밀리초)을 사용 하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-221">We recommend using a timeout (for example, 500–1500 ms) to determine whether to switch or not.</span></span> <span data-ttu-id="fd2f4-222">이 작업을 수행 하면 빠른 눈 동작 또는 윙크 및 깜박이 때문에 시스템이 일시적으로 추적을 손실할 수 있는 경우에도 커서가 나타나지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-222">This action prevents cursors from appearing every time the system may briefly lose tracking because of fast eye motions or winks and blinks.</span></span> <span data-ttu-id="fd2f4-223">Unity 개발자 인 경우 head-응시에 대 한 자동 대체는 혼합 현실 도구 키트에서 이미 처리 되었습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-223">If you're a Unity developer, the automatic fallback to head-gaze is already handled in the Mixed Reality Toolkit.</span></span> <span data-ttu-id="fd2f4-224">DirectX 개발자 라면이 스위치를 직접 처리 해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-224">If you're a DirectX developer, you need to handle this switch yourself.</span></span>

### <a name="fall-back-for-other-eye-tracking-specific-applications"></a><span data-ttu-id="fd2f4-225">다른 눈 추적 관련 응용 프로그램을 대체 합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-225">Fall back for other eye-tracking-specific applications</span></span>

<span data-ttu-id="fd2f4-226">앱은 눈에 맞게 조정 된 고유한 방식으로 눈에 잘 맞는 방식을 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-226">Your app may use eye-gaze in a unique way that is tailored specifically to the eyes.</span></span> <span data-ttu-id="fd2f4-227">예를 들어 아바타의 눈에 애니메이션을 적용 하거나 눈에 잘 맞는 주의가 필요한 경우 시각적 주의 사항에 대 한 정확한 정보를 열 지도.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-227">For example, animating an avatar’s eyes or for eye-based attention heatmaps relying on precise information about visual attention.</span></span> <span data-ttu-id="fd2f4-228">이 경우에는 명확한 대체 (fallback)가 없습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-228">In this case, there's no clear fallback.</span></span> <span data-ttu-id="fd2f4-229">눈동자 추적을 사용할 수 없는 경우 이러한 기능을 사용 하지 않도록 설정 해야 할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-229">If eye tracking isn't available, these capabilities may need to be disabled.</span></span>
<span data-ttu-id="fd2f4-230">기능이 제대로 작동 하지 않는다는 것을 모를 수 있는 사용자에 게이를 명확 하 게 전달 하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-230">Again, we recommend to clearly communicate this to the user who may be unaware that the capability isn't working.</span></span>

<br>

<span data-ttu-id="fd2f4-231">이 페이지에서는 HoloLens 2에 대 한 눈에 보기 및 눈에 잘 맞는 입력의 역할을 이해 하기 시작 하는 데 도움이 되는 유용한 개요를 제공 합니다.</span><span class="sxs-lookup"><span data-stu-id="fd2f4-231">This page has hopefully provided you with a good overview to get you started understanding the role of eye tracking and eye-gaze input for HoloLens 2.</span></span> <span data-ttu-id="fd2f4-232">개발을 시작 하려면 [holograms와의 상호 작용을 위해 눈길](eye-gaze-interaction.md)을 [내](https://aka.ms/mrtk-eyes) 는 역할에 대 한 정보를 확인 [하세요.](../develop/native/gaze-in-directx.md)</span><span class="sxs-lookup"><span data-stu-id="fd2f4-232">To get started developing, check out our information on the role of [eye-gaze for interacting with holograms](eye-gaze-interaction.md), [eye-gaze in Unity](https://aka.ms/mrtk-eyes) and [eye-gaze in DirectX](../develop/native/gaze-in-directx.md).</span></span>

## <a name="see-also"></a><span data-ttu-id="fd2f4-233">참고 항목</span><span class="sxs-lookup"><span data-stu-id="fd2f4-233">See also</span></span>

* [<span data-ttu-id="fd2f4-234">조정</span><span class="sxs-lookup"><span data-stu-id="fd2f4-234">Calibration</span></span>](/hololens/hololens-calibration)
* [<span data-ttu-id="fd2f4-235">편안함</span><span class="sxs-lookup"><span data-stu-id="fd2f4-235">Comfort</span></span>](comfort.md)
* [<span data-ttu-id="fd2f4-236">시선 응시 기반 상호 작용</span><span class="sxs-lookup"><span data-stu-id="fd2f4-236">Eye-gaze-based interaction</span></span>](eye-gaze-interaction.md)
* [<span data-ttu-id="fd2f4-237">눈-DirectX에서 응시</span><span class="sxs-lookup"><span data-stu-id="fd2f4-237">Eye-gaze in DirectX</span></span>](../develop/native/gaze-in-directx.md)
* [<span data-ttu-id="fd2f4-238">눈동자-Unity에서 응시 (혼합 현실 도구 키트)</span><span class="sxs-lookup"><span data-stu-id="fd2f4-238">Eye-gaze in Unity (Mixed Reality Toolkit)</span></span>](https://aka.ms/mrtk-eyes)
* [<span data-ttu-id="fd2f4-239">응시 및 커밋</span><span class="sxs-lookup"><span data-stu-id="fd2f4-239">Gaze and commit</span></span>](gaze-and-commit.md)
* [<span data-ttu-id="fd2f4-240">음성 입력 </span><span class="sxs-lookup"><span data-stu-id="fd2f4-240">Voice input</span></span>](../out-of-scope/voice-design.md)
